parameters.to.save = c('b','sigma', 'rho' ),model.file = jagsmodelSMSC,
n.chains=2,n.iter = 50000,n.burnin = 10000,n.thin = 10)
#results
print(SMSCjagsResults)
load("C:/Users/kc19o338/Desktop/old profile/Desktop/Real world predictions project/PrognosticModelMI10.RData")
#table of all Bayesian results from each one of the imputed datasets
tablewithresults
## Step 4: use the Rubin's rules to pool the stimates & table with all the estimates in the inputed datasets
source("PooledEstimates.R")
#table of all Bayesian results from each one of the imputed datasets
tablewithresults
#pooled estimates
Pooled
exp(0.019)
exp(0.019/(1+0.019))
exp(-0.035)
exp(0.322)
exp(0.124)
exp(0.036)
exp(-0.076)
exp(0.120)
exp(-0.448)
exp(-0.482)
exp(0.079)
exp(0.253)
exp(-0.220)
## creation of two new columns with the predicted risk of SMSC individuals and the predicted logit risk
source("SMSCRiskDataset.R")
SMSCRiskDataset
SMSCdataC$Risk
summary(SMSCdataC$Risk)
SMSCdataC2<-SMSCdataC[which(SMSCdataC$Risk>=0.15),]
SMSCdataC3<-SMSCdataC2[which(SMSCdataC$Risk<=0.30),]
lenght(SMSCdataC3)
nrow(SMSCdataC3)
summary(SMSCdataC3$Risk)
SMSCdataC3<-SMSCdataC2[which(SMSCdataC2$Risk<=0.30),]
nrow(SMSCdataC3)
length(unique(SMSCdataC3$patient.id))
length(unique(SMSCdataC$patient.id))
length(unique(SMSCdata$patient.id))
277/610
server <- function(input, output, session) {
log.risk.score=reactive( -1.884607+0.3491485-0.03529109*(input$Age-42.65153)+0.3224459*(log(input$DiseaseDuration+10)-2.9947)+0.1242894*(input$EDSS-2.458)+0.03572392*input$GdLesions-0.07593726*input$NrRelapses1+0.1201103*input$NrRelapses2-0.481536*(log(input$MonthsSinceLastRelapse+10)-3.80)+0.07933781*input$TrNaive+0.2527921*input$Gender)
risk.score1 = reactive(exp(log.risk.score())/(1+exp(log.risk.score())))
risk.score2=reactive(round(risk.score1(),2))
risk.score=reactive(risk.score2()*100)
data <- reactive({
x<-19.2
y<-risk.score()
z<-(c("1","2"))
z<-as.factor(z)
z<-as.data.frame(z)
w<-as.data.frame(rbind(x,y))
m<-as.data.frame(cbind(w,z))
colnames(m)<-c("Predicted probability (%) to relape at 2 years", "Category")
m<-as.data.frame(m)
})
output$final.risk.score <- renderText({
paste("Your risk to relapse at 2 years is", as.integer(risk.score()), "%")
})
output$plot <- renderPlot({
ggplot(data(), aes(x=Category, y=`Predicted probability (%) to relape at 2 years`)) + ylim(0,50) +
geom_bar(stat="identity", position=position_dodge(), color=c("lightblue","orange"), fill=c("lightblue","orange"),width=0.1)+  theme(text = element_text(size = 17))+labs(x="") +
geom_errorbar(aes(ymin=18.6, ymax=19.7), width=.05, size=2,
position=position_dodge(.9)) +theme(axis.text.x = element_text(size=20)) + scale_x_discrete(labels=c("Average", paste("Somebody with", "your", "characteristics"))) + ggtitle("Plot of predicted probabilities (%) to relapse at 2 years")
})
output$final.text1 <- renderText({
paste("The average predicted probability (%) to relapse at 2 years is 19.2 with 95% C.I. (18.6, 19.7)")
})
output$final.text2 <- renderText({
paste("Somebody with your characteristics has", risk.score(), "% predicted probability (%) to relapse at 2 years")
})
output$final.text3 <- renderText({
if (risk.score()>=19.2) {
paste("Your predicted probability (%) to relapse at 2 years is", risk.score()-19.2, "% higher than the average")
}
})
output$final.text4 <- renderText({
if (risk.score()<19.2) {
paste("Your predicted probability (%) to relapse at 2 years is", 19.2-risk.score(), "% lower than the average")
}
})
output$final.text <- renderText({
paste("Numerical Results:")
})
}
ui <-  fluidPage(theme=shinytheme("readable"),
titlePanel(h1("Prevention of relapses in patients with Relapsing-Remitting Multiple Sclerosis")), # using strong as a direct tag
#h1("Using textInput and checkboxInput")
sidebarLayout(
sidebarPanel(
sliderInput(inputId = "Age",
label = "Age (years)",
value = 1, min = 17, max = 80),
numericInput(inputId="DiseaseDuration", label="Disease Duration (years)",value=1, min=0,max=70, step=0.1),
sliderInput(inputId="EDSS", label="EDSS",value=1, min=0,max=7,step=0.5),
checkboxInput(inputId="GdLesions", label="Number of Gadolinium enhanced lesions > 0"),
checkboxInput(inputId="NrRelapses1", label="1 prior relapse"),
checkboxInput(inputId="NrRelapses2", label="2 or more prior relapses"),
numericInput(inputId="MonthsSinceLastRelapse", label="Months since last relapse",value=1, min=0,max=600, step=0.1),
checkboxInput(inputId="TrNaive", label="Treatment Naive"),
checkboxInput(inputId="Gender", label="Female")),
mainPanel(  span(h3(textOutput("final.risk.score")),style="color:blue"),
plotOutput("plot"),
span(h3(textOutput("final.text")),style="color:green"),
h4(textOutput("final.text1")),
h4(textOutput("final.text2")),
h4(textOutput("final.text3")),
h4(textOutput("final.text4"))
)
)
)
shinyApp(ui = ui, server = server)
##########################################################
############### LIBRARIES #################################
### Load needed libraries
library(readxl)
library(dplyr)
library(rms)
library(lme4)
library(R2jags)
library(mitml)
library(jomo)
library(xlsx)
library(ggpubr)
library(gridExtra)
library(devtools)
library(pROC)
library(vcd)
library(plyr)
library(pmsampsize)
library(shiny)
library(shinythemes)
library(devtools)
install_git("https://github.com/BavoDC/CalibrationCurves")
library(CalibrationCurves)
# give/change your datapath (the datapath that includes the data)
mydatapath="C:/Users/kc19o338/Desktop/SMSC"
########################## DATASET NEEDED FOR THE PRE-SPECIFIED PROGNOSTIC MODEL ##############################
# function that keeps only the needed variables (selected via pre-existing prognostic models on the literature, for RRMS patients)
# and makses the proper transformations for continues and categorical variables
# (in case you want to see all summary statistics for the SMSC data before and after the transformations you can run the SMSC_Summary.R script)
source("R/FinalDataSMSC.fun.R")
SMSCdata<-FinalDataSMSC.fun(mydatapath)
# give/change your datapath (the datapath that includes the data)
mydatapath="C:/Users/kc19o338/Desktop/SMSC"
########################## DATASET NEEDED FOR THE PRE-SPECIFIED PROGNOSTIC MODEL ##############################
# function that keeps only the needed variables (selected via pre-existing prognostic models on the literature, for RRMS patients)
# and makses the proper transformations for continues and categorical variables
# (in case you want to see all summary statistics for the SMSC data before and after the transformations you can run the SMSC_Summary.R script)
source("R/FinalDataSMSC.fun.R")
SMSCdata<-FinalDataSMSC.fun(mydatapath)
# the dataset with complete cases only, no missing values at all
SMSCdataC<-na.omit(SMSCdata)
View(SMSCdataC)
View(SMSCdataC)
source("Frequentist_glmm.R")
#the results of the mixed-effects model
summary(glmer_out)
# compare them with a model with fixed effects only (glm)
summary(glm_out)
#the results of the mixed-effects model
summary(glmer_out)
# compare them with a model with fixed effects only (glm)
summary(glm_out)
#check if resstricted cubic splines are needed
source("Check_rcs.R")
glm_rcs<-lrm((outcome)~ rcs(age,4) + rcs(disease.duration,4) + rcs(edss,4) + nr.Gd.enhanced.lesions + nr.relapses.2y.prior.study +
rcs(months.since.last.relapse,4) + treatment.naive.prior.visit + gender + treatment.during.cycle,
x=TRUE,y=TRUE,data=SMSCdata_glmer,maxit=1000)
anova(glm_rcs) #none of the variables has non-linear relationship with the outcome
########################## DATASET NEEDED FOR THE PRE-SPECIFIED PROGNOSTIC MODEL ##############################
# function that keeps only the needed variables (selected via pre-existing prognostic models on the literature, for RRMS patients)
# and makses the proper transformations for continues and categorical variables
# (in case you want to see all summary statistics for the SMSC data before and after the transformations you can run the SMSC_Summary.R script)
source("R/FinalDataSMSC.fun.R")
SMSCdata<-FinalDataSMSC.fun(mydatapath)
# the dataset with complete cases only, no missing values at all
SMSCdataC<-na.omit(SMSCdata)
#check if resstricted cubic splines are needed
source("Check_rcs.R")
anova(glm_rcs) #it seems that there is no variable with non-linear relationhip
##### Read the data needed for the jags model
source("DataJagsPrM.R")
#source the jags model
source("R/jagsmodelSMSC.R")
# give initial values for the jags model
jags.inits <- function(){
list("b"=c(0,0,0,0,0,0,0,0,0,0,0),"sigma"=0.02,"rho"=0.4)
}
# run the jugs model
set.seed(2000)
SMSCjagsResults <- jags.parallel(data = jagsdataSMSC ,inits= jags.inits,
parameters.to.save = c('b','sigma', 'rho' ),model.file = jagsmodelSMSC,
n.chains=2,n.iter = 50000,n.burnin = 10000,n.thin = 10)
library(R2jags)
install.packages("R"jags)
install.packages("R2jags)
install.packages("R2jags")
library(R2jags)
install.packages("Rjags")
library(R2jags)
install.packages("JAGS")
library(R2jags)
install.packages("JAGS-4.x.y.exe ")
library(R2jags)
SMSCjagsResults <- jags.parallel(data = jagsdataSMSC ,inits= jags.inits,
parameters.to.save = c('b','sigma', 'rho' ),model.file = jagsmodelSMSC,
n.chains=2,n.iter = 50000,n.burnin = 10000,n.thin = 10)
load("C:/Users/kc19o338/Desktop/Real world predictions project/PrognosticModelMI10.RData")
#pooled estimates
Pooled
## Step 4: use the Rubin's rules to pool the stimates & table with all the estimates in the inputed datasets
source("PooledEstimates.R")
#results
print(SMSCjagsResults)
#pooled estimates
Pooled
## creation of two new columns with the predicted risk of SMSC individuals and the predicted logit risk
source("SMSCRiskDataset.R")
### plot of the distribution of Risk in SMSC
source("PlotsPrognosticModel.R")
RiskDistribution
RiskPrFactor
########################  APPARENT VALIDATION  & Graphs   ############
source("ApparentValidationPrModel.R")
app_cstat_model
mod_log_2
confint(mod_log_2)
####################################  Calibration Plot  #################################################################
val.prob.ci.2(SMSCdataC$Risk, as.numeric(SMSCdataC$outcome)-1, xlim=c(0,0.8))
library(CalibrationCurves)
install.packages("CalibrationCurves")
library(CalibrationCurves)
library(BavoDC/CalibrationCurves)
install_git("https://github.com/BavoDC/CalibrationCurves")
library(gridExtra)
library(devtools)
library(devtools)
install_git("https://github.com/BavoDC/CalibrationCurves")
install_github("https://github.com/BavoDC/CalibrationCurves")
####################################  Calibration Plot  #################################################################
val.prob.ci.2(SMSCdataC$Risk, as.numeric(SMSCdataC$outcome)-1, xlim=c(0,0.8))
library(CalibrationCurves)
####################################  Calibration Plot  #################################################################
val.prob.ci.2(SMSCdataC$Risk, as.numeric(SMSCdataC$outcome)-1, xlim=c(0,0.8))
########################  Calculation of the EPV and the required sample size based on Riley et al   ############
source("EPVandSampleSizePrModel.R")
df<-22
events<-nrow(SMSCdata[which(SMSCdata$outcome==1),])
EPV<-events/df
#### sample size by Riley et al
#null model
mod0 <- lrm(outcome~1,x=TRUE,y=TRUE,data=SMSCdata)
help(lrm)
#### sample size by Riley et al
#null model
mod0 <- lrm(outcome~1,x=TRUE,y=TRUE,data=SMSCdata,strata.penalty=0)
MaxRcs<-(1-exp(2*as.numeric(logLik(mod0)/1752)))
lrm(outcome~1,x=TRUE,y=TRUE,data=SMSCdata)
##################################### DECISION CURVE ANALYSIS ##################################################
source("R/dca.fun.R")
SMSCdataC$outcome2<-as.numeric(SMSCdataC$outcome)-1
SMSCdataC$PrognosticModel<-SMSCdataC$Risk
SMSCdataC<-as.data.frame(SMSCdataC)
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel", xstop = 0.5)
SMSCdataC$outcome2
SMSCdataC$PrognosticModel
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel", xstop = 0.5)
##centralize the variables
source("imp_centralize.R")
SMSCdataC$outcome2
SMSCdataC$PrognosticModel
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel")
SMSCdataC$outcome
SMSCdataC$outcome
SMSCdataC$outcome
dca.fun(data=SMSCdataC, outcome="outcome", predictors="PrognosticModel")
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel")
#INITIALIZING EMPTY PLOT WITH LABELS
plot(x=nb$threshold, y=nb$all, type="n" ,xlim=c(xstart, xstop), ylim=c(ymin, ymax), xlab="Threshold probability", ylab=paste("Net reduction in interventions per",interventionper,"patients"))
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel")
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel")
##################################### DECISION CURVE ANALYSIS ##################################################
source("R/dca.fun.R")
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel")
# LOADING REQUIRED LIBRARIES
require(stats)
plot(x=net.benefit$threshold, y=nb$all, type="l", col=8, lwd=2 ,xlim=c(xstart, xstop), ylim=c(ymin, ymax), xlab="Threshold probability", ylab="Net benefit")
data<-SMSCdataC
# data MUST BE A DATA FRAME
if (class(data)!="data.frame") {
stop("Input data must be class data.frame")
}
#ONLY KEEPING COMPLETE CASES
data=data[complete.cases(data[append(outcome,predictors)]),append(outcome,predictors)]
predictors<-SMSCdataC$PrognosticModel
outcome<-SMSCdataC$outcome2
#ONLY KEEPING COMPLETE CASES
data=data[complete.cases(data[append(outcome,predictors)]),append(outcome,predictors)]
# outcome MUST BE CODED AS 0 AND 1
if (max(data[[outcome]])>1 | min(data[[outcome]])<0) {
stop("outcome cannot be less than 0 or greater than 1")
}
# xstart IS BETWEEN 0 AND 1
if (xstart<0 | xstart>1) {
stop("xstart must lie between 0 and 1")
}
# xstop IS BETWEEN 0 AND 1
if (xstop<0 | xstop>1) {
stop("xstop must lie between 0 and 1")
}
# xby IS BETWEEN 0 AND 1
if (xby<=0 | xby>=1) {
stop("xby must lie between 0 and 1")
}
# xstart IS BEFORE xstop
if (xstart>=xstop) {
stop("xstop must be larger than xstart")
}
#STORING THE NUMBER OF PREDICTORS SPECIFIED
pred.n=length(predictors)
#IF probability SPECIFIED ENSURING THAT EACH PREDICTOR IS INDICATED AS A YES OR NO
if (length(probability)>0 & pred.n!=length(probability)) {
stop("Number of probabilities specified must be the same as the number of predictors being checked.")
}
#CHECKING THAT EACH probability ELEMENT IS EQUAL TO YES OR NO,
#AND CHECKING THAT PROBABILITIES ARE BETWEEN 0 and 1
#IF NOT A PROB THEN CONVERTING WITH A LOGISTIC REGRESSION
for(m in 1:pred.n) {
if (probability[m]!=TRUE & probability[m]!=FALSE) {
stop("Each element of probability vector must be TRUE or FALSE")
}
if (probability[m]==TRUE & (max(data[predictors[m]])>1 | min(data[predictors[m]])<0)) {
stop(paste(predictors[m],"must be between 0 and 1 OR sepcified as a non-probability in the probability option",sep=" "))
}
if(probability[m]==FALSE) {
model=NULL
pred=NULL
model=glm(data.matrix(data[outcome]) ~ data.matrix(data[predictors[m]]), family=binomial("logit"))
pred=data.frame(model$fitted.values)
pred=data.frame(pred)
names(pred)=predictors[m]
data=cbind(data[names(data)!=predictors[m]],pred)
print(paste(predictors[m],"converted to a probability with logistic regression. Due to linearity assumption, miscalibration may occur.",sep=" "))
}
}
#########  CALCULATING NET BENEFIT   #########
N=dim(data)[1]
event.rate=colMeans(data[outcome])
# CREATING DATAFRAME THAT IS ONE LINE PER THRESHOLD PER all AND none STRATEGY
nb=data.frame(seq(from=xstart, to=xstop, by=xby))
xstart<-0.1
xstop<-0.8
xstart<-0.01
# CREATING DATAFRAME THAT IS ONE LINE PER THRESHOLD PER all AND none STRATEGY
nb=data.frame(seq(from=xstart, to=xstop, by=xby))
xstart=0.01
xstop=0.99
xby=0.01
ymin=-0.05
probability=NULL
harm=NULL
graph=TRUE
intervention=FALSE
interventionper=100
smooth=FALSE
loess.span=0.10
# LOADING REQUIRED LIBRARIES
require(stats)
# data MUST BE A DATA FRAME
if (class(data)!="data.frame") {
stop("Input data must be class data.frame")
}
#ONLY KEEPING COMPLETE CASES
data=data[complete.cases(data[append(outcome,predictors)]),append(outcome,predictors)]
# outcome MUST BE CODED AS 0 AND 1
if (max(data[[outcome]])>1 | min(data[[outcome]])<0) {
stop("outcome cannot be less than 0 or greater than 1")
}
# xstart IS BETWEEN 0 AND 1
if (xstart<0 | xstart>1) {
stop("xstart must lie between 0 and 1")
}
# xstop IS BETWEEN 0 AND 1
if (xstop<0 | xstop>1) {
stop("xstop must lie between 0 and 1")
}
# xby IS BETWEEN 0 AND 1
if (xby<=0 | xby>=1) {
stop("xby must lie between 0 and 1")
}
# xstart IS BEFORE xstop
if (xstart>=xstop) {
stop("xstop must be larger than xstart")
}
#STORING THE NUMBER OF PREDICTORS SPECIFIED
pred.n=length(predictors)
#IF probability SPECIFIED ENSURING THAT EACH PREDICTOR IS INDICATED AS A YES OR NO
if (length(probability)>0 & pred.n!=length(probability)) {
stop("Number of probabilities specified must be the same as the number of predictors being checked.")
}
#IF harm SPECIFIED ENSURING THAT EACH PREDICTOR HAS A SPECIFIED HARM
if (length(harm)>0 & pred.n!=length(harm)) {
stop("Number of harms specified must be the same as the number of predictors being checked.")
}
#INITIALIZING DEFAULT VALUES FOR PROBABILITES AND HARMS IF NOT SPECIFIED
if (length(harm)==0) {
harm=rep(0,pred.n)
}
if (length(probability)==0) {
probability=rep(TRUE,pred.n)
}
#CHECKING THAT EACH probability ELEMENT IS EQUAL TO YES OR NO,
#AND CHECKING THAT PROBABILITIES ARE BETWEEN 0 and 1
#IF NOT A PROB THEN CONVERTING WITH A LOGISTIC REGRESSION
for(m in 1:pred.n) {
if (probability[m]!=TRUE & probability[m]!=FALSE) {
stop("Each element of probability vector must be TRUE or FALSE")
}
if (probability[m]==TRUE & (max(data[predictors[m]])>1 | min(data[predictors[m]])<0)) {
stop(paste(predictors[m],"must be between 0 and 1 OR sepcified as a non-probability in the probability option",sep=" "))
}
if(probability[m]==FALSE) {
model=NULL
pred=NULL
model=glm(data.matrix(data[outcome]) ~ data.matrix(data[predictors[m]]), family=binomial("logit"))
pred=data.frame(model$fitted.values)
pred=data.frame(pred)
names(pred)=predictors[m]
data=cbind(data[names(data)!=predictors[m]],pred)
print(paste(predictors[m],"converted to a probability with logistic regression. Due to linearity assumption, miscalibration may occur.",sep=" "))
}
}
# THE PREDICTOR NAMES CANNOT BE EQUAL TO all OR none.
if (length(predictors[predictors=="all" | predictors=="none"])) {
stop("Prediction names cannot be equal to all or none.")
}
#########  CALCULATING NET BENEFIT   #########
N=dim(data)[1]
event.rate=colMeans(data[outcome])
colMeans(data[outcome])
data[outcome]
outcome<-SMSCdataC$outcome2
outcome
SMSCdataC[outcome2]
SMSCdataC[SMSCdataC$outcome2]
# CREATING DATAFRAME THAT IS ONE LINE PER THRESHOLD PER all AND none STRATEGY
nb=data.frame(seq(from=xstart, to=xstop, by=xby))
names(nb)="threshold"
interv=nb
nb["all"]=event.rate - (1-event.rate)*nb$threshold/(1-nb$threshold)
SMSCdataC[SMSCdataC$outcome2]
colMeans(SMSCdataC$outcome2)
mean(SMSCdataC$outcome2)
event.rate=mean(outcome)
# CREATING DATAFRAME THAT IS ONE LINE PER THRESHOLD PER all AND none STRATEGY
nb=data.frame(seq(from=xstart, to=xstop, by=xby))
names(nb)="threshold"
interv=nb
nb["all"]=event.rate - (1-event.rate)*nb$threshold/(1-nb$threshold)
nb["none"]=0
# CYCLING THROUGH EACH PREDICTOR AND CALCULATING NET BENEFIT
for(m in 1:pred.n){
for(t in 1:length(nb$threshold)){
# COUNTING TRUE POSITIVES AT EACH THRESHOLD
tp=mean(data[data[[predictors[m]]]>=nb$threshold[t],outcome])*sum(data[[predictors[m]]]>=nb$threshold[t])
# COUNTING FALSE POSITIVES AT EACH THRESHOLD
fp=(1-mean(data[data[[predictors[m]]]>=nb$threshold[t],outcome]))*sum(data[[predictors[m]]]>=nb$threshold[t])
#setting TP and FP to 0 if no observations meet threshold prob.
if (sum(data[[predictors[m]]]>=nb$threshold[t])==0) {
tp=0
fp=0
}
# CALCULATING NET BENEFIT
nb[t,predictors[m]]=tp/N - fp/N*(nb$threshold[t]/(1-nb$threshold[t])) - harm[m]
}
interv[predictors[m]]=(nb[predictors[m]] - nb["all"])*interventionper/(interv$threshold/(1-interv$threshold))
}
##################################### DECISION CURVE ANALYSIS ##################################################
source("R/dca.fun.R")
SMSCdataC$outcome2<-as.numeric(SMSCdataC$outcome)-1
SMSCdataC$PrognosticModel<-SMSCdataC$Risk
SMSCdataC<-as.data.frame(SMSCdataC)
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel")
##################################### DECISION CURVE ANALYSIS ##################################################
source("R/dca.fun.R")
SMSCdataC$outcome2<-as.numeric(SMSCdataC$outcome)-1
SMSCdataC$PrognosticModel<-SMSCdataC$Risk
SMSCdataC<-as.data.frame(SMSCdataC)
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel")
############################# R-shiny app ##################################################################
source('R-shinyPr.R')
############################# R-shiny app ##################################################################
source('R-shinyPr.R')
shinyApp(ui = ui, server = server) #also available in https://cinema.ispm.unibe.ch/shinies/rrms/
##centralize the variables
source("imp_centralize.R")
##centralize the variables
source("imp_centralize.R")
#source the function for bootstrap validation
source("R/BootstrapValidation_PrModel.fun.R")
optimism_AUC<-NA
for (i in (1:10)){
optimism_AUC[i]<-BootstrapValidation_PrModel.fun(imp.list1[[i]], samples=500)
}
##################################### DECISION CURVE ANALYSIS ##################################################
source("R/dca.fun.R")
SMSCdataC$outcome2<-as.numeric(SMSCdataC$outcome)-1
SMSCdataC$PrognosticModel<-SMSCdataC$Risk
dca.fun(data=SMSCdataC, outcome="outcome2", predictors="PrognosticModel", xstop = 0.4)
